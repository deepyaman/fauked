# Here you can define all your data sets by using simple YAML syntax.
#
# Documentation for this file format can be found in "The Data Catalog"
# Link: https://kedro.readthedocs.io/en/stable/04_user_guide/04_data_catalog.html
example_creditcard_data:
  type: pandas.CSVDataSet
  filepath: data/01_raw/creditcard.csv

streaming_creditcard_data:
  type: fauked.io.SparkStreamingDataSet
  filepath: ignore
  file_format: kafka
  load_args:
    kafka.bootstrap.servers: "localhost:19092"
    subscribe: "hello-fraud"
    startingOffsets: latest

mlflow_model:
  type: pandas.CSVDataSet
  filepath: data/01_raw/creditcard.csv

streaming_predictions:
  type: fauked.io.SparkStreamingDataSet
  filepath: ignore
  file_format: console

# streaming_predictions:
#   type: fauked.io.SparkStreamingDataSet
#   filepath: ignore
#   file_format: kafka
#   save_args:
#     output_mode: append
#     kafka.bootstrap.servers: "localhost:19092"
#     topic: "hello-predictions"
#     checkpointLocation: checkpoints
