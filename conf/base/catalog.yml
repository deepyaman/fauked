# Here you can define all your data sets by using simple YAML syntax.
#
# Documentation for this file format can be found in "The Data Catalog"
# Link: https://kedro.readthedocs.io/en/stable/04_user_guide/04_data_catalog.html
example_creditcard_data:
  type: pandas.ParquetDataSet
  filepath: data/01_raw/creditcard.parquet

streaming_creditcard_data:
  type: kedro_streaming.io.SparkStreamingDataSet
  file_format: kafka
  load_args:
    kafka.bootstrap.servers: "localhost:19092"
    subscribe: "hello-fraudster"
    startingOffsets: latest

example_model:
  type: kedro_streaming.io.MLFlowDataSet
  tracking_uri: http://localhost:5000
  experiment_name: example
  model_name: example_regressor

streaming_predictions:
  type: kedro_streaming.io.SparkStreamingDataSet
  file_format: console
# streaming_predictions:
#   type: kedro_streaming.io.SparkStreamingDataSet
#   file_format: kafka
#   save_args:
#     output_mode: append
#     kafka.bootstrap.servers: "localhost:19092"
#     topic: "hello-predictions"
#     checkpointLocation: checkpoints
