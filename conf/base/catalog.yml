# Here you can define all your data sets by using simple YAML syntax.
#
# Documentation for this file format can be found in "The Data Catalog"
# Link: https://kedro.readthedocs.io/en/stable/04_user_guide/04_data_catalog.html
example_creditcard_data:
  type: pandas.ParquetDataSet
  filepath: data/01_raw/creditcard.parquet

streaming_creditcard_data:
  type: fauked.io.SparkStreamingDataSet
  filepath: ignore
  file_format: kafka
  load_args:
    kafka.bootstrap.servers: "localhost:19092"
    subscribe: "hello-fraud"
    startingOffsets: latest

fauked_regressor:
  type: fauked.io.mlflow_dataset.MLFlowDataSet
  tracking_uri: http://localhost:5000
  experiment_name: fauked
  model_name: fauked_regressor

streaming_predictions:
  type: fauked.io.SparkStreamingDataSet
  filepath: ignore
  file_format: console
# streaming_predictions:
#   type: fauked.io.SparkStreamingDataSet
#   filepath: ignore
#   file_format: kafka
#   save_args:
#     output_mode: append
#     kafka.bootstrap.servers: "localhost:19092"
#     topic: "hello-predictions"
#     checkpointLocation: checkpoints
